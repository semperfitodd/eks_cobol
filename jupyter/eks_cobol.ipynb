{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setup and Configuration\n",
    "\n",
    "This section initializes the SageMaker environment, defines the S3 paths, and sets up the IAM role and session to be used throughout the notebook."
   ],
   "id": "27408e6cdd353dfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install --upgrade awscli s3fs\n",
    "!pip install --upgrade boto3\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = 'eks-cobol-logs-730pkp'\n",
    "prefix = 'training'\n",
    "\n",
    "role = get_execution_role()"
   ],
   "id": "58ffaaca1f6d57ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Load and Explore Data\n",
    "\n",
    "This section loads the training data from S3 and performs basic inspection of the dataset to understand its structure and content.\n"
   ],
   "id": "ffadbc6f00029760"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "s3_uri = f's3://{bucket}/{prefix}/training-data.csv'\n",
    "df = pd.read_csv(s3_uri)\n",
    "\n",
    "print(\"Sample Data:\")\n",
    "display(df.head())\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(df['label'].value_counts())"
   ],
   "id": "57637a2beb21070b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Preprocess Data\n",
    "\n",
    "This section encodes the categorical `description` column and prepares the features and labels. The dataset is then split into training and test sets using stratified sampling to preserve class distribution.\n"
   ],
   "id": "70be486f321fdf35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df['description'] = df['description'].astype(\"category\").cat.codes\n",
    "features = df.drop(\"label\", axis=1)\n",
    "labels = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")"
   ],
   "id": "e7e239c8c5d068c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Save and Upload Train/Test Sets to S3\n",
    "\n",
    "The training and testing datasets are saved locally and uploaded to S3 so they can be used by the SageMaker training job.\n"
   ],
   "id": "ca5a223bad10b544"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_data = pd.concat([y_train, X_train], axis=1)\n",
    "test_data = pd.concat([y_test, X_test], axis=1)\n",
    "\n",
    "train_file = 'train.csv'\n",
    "test_file = 'test.csv'\n",
    "\n",
    "train_data.to_csv(train_file, header=False, index=False)\n",
    "test_data.to_csv(test_file, header=False, index=False)\n",
    "\n",
    "train_s3_path = session.upload_data(train_file, bucket=bucket, key_prefix=f'{prefix}/xgboost')\n",
    "test_s3_path = session.upload_data(test_file, bucket=bucket, key_prefix=f'{prefix}/xgboost')"
   ],
   "id": "989b5fc34a2bdd45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train XGBoost Model\n",
    "\n",
    "This section defines the XGBoost training job using SageMaker's built-in XGBoost container. It specifies the hyperparameters and starts the training job using the datasets uploaded to S3.\n"
   ],
   "id": "bb2e582c8e61ef65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", session.boto_region_name, \"1.3-1\")\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=100,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "xgb_estimator.fit({\n",
    "    \"train\": TrainingInput(train_s3_path, content_type=\"csv\"),\n",
    "    \"validation\": TrainingInput(test_s3_path, content_type=\"csv\")\n",
    "})\n"
   ],
   "id": "98da30cc167c88c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Deploy Model and Test Inference\n",
    "\n",
    "This section deploys the trained model to a SageMaker endpoint and performs a prediction on a sample row from the test set.\n"
   ],
   "id": "b0ac6ab612e87399"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = xgb_estimator.deploy(initial_instance_count=1, instance_type=\"ml.p3.2xlarge\")\n",
    "predictor.serializer = CSVSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "sample = X_test.head(1).to_csv(header=False, index=False).strip()\n",
    "print(\"Sample row:\", sample)\n",
    "print(\"Prediction:\", predictor.predict(sample))\n"
   ],
   "id": "b0ddfec32f86aaed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluate the Model\n",
    "\n",
    "This section evaluates the model performance using standard metrics and displays a confusion matrix.\n"
   ],
   "id": "f264e2e388798b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Run batch prediction\n",
    "y_pred_proba = predictor.predict(X_test.to_csv(header=False, index=False))['predictions']\n",
    "y_pred = [int(float(p['score']) > 0.5) for p in y_pred_proba]\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Valid\", \"Error\"])\n",
    "disp.plot(cmap=\"Blues\")"
   ],
   "id": "ac221dd0eb2d3af1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cleanup\n",
    "\n",
    "This section deletes the deployed endpoint to avoid incurring charges.\n"
   ],
   "id": "44494f2238ca24f9"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "predictor.delete_endpoint()",
   "id": "22a99a4cb68fbe4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
